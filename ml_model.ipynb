{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from prophet import Prophet\n",
    "\n",
    "from src.metrics import evaluate\n",
    "from src.models import aggregated_daily_predictions, BaselineYearAgo\n",
    "from src.process_data import read_datasets, prepare_dataset\n",
    "from src.plots import plot_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentTracker:\n",
    "    def __init__(self) -> None:\n",
    "        self.experiments = []\n",
    "        self._current_run_id = 0\n",
    "\n",
    "    def add_experiment(self, model, train, test, name = None, predict_function = None):\n",
    "        if name == None:\n",
    "            name = \"experiment\" + str(self._run_id)\n",
    "        assert name not in [item['name'] for item in self.experiments], \"Name must be unit\"\n",
    "\n",
    "        if isinstance(model, Prophet):\n",
    "            predict_function = lambda df: model.predict(df)['yhat']\n",
    "        if predict_function == None:\n",
    "            predict_function = model.predict\n",
    "        \n",
    "        train = train.copy()\n",
    "        test = test.copy()\n",
    "\n",
    "        train['predict'] = predict_function(train.drop('target', axis=1))\n",
    "        test['predict'] = predict_function(test.drop('target', axis=1))\n",
    "\n",
    "        experiment = {\n",
    "            'name': name if name != \"\" else str(model),\n",
    "            'run_id': self._current_run_id,\n",
    "            'model': model,\n",
    "            'train': train.copy(),\n",
    "            'test': test.copy()\n",
    "        }\n",
    "\n",
    "        experiment.update({f\"train_{k}\": v for k, v in evaluate(train['target'], train['predict']).items()})\n",
    "        experiment.update({f\"test_{k}\": v for k, v in evaluate(test['target'], test['predict']).items()})\n",
    "        # experiment.update(pd.json_normalize(evaluate(test['target'], test['predict'])).add_prefix('test_').iloc[0].to_dict())\n",
    "\n",
    "        self.experiments.append(experiment)\n",
    "        self._current_run_id += 1\n",
    "\n",
    "    def get_experiment(self, name):\n",
    "        for item in self.experiments:\n",
    "            if item['name'] == name:\n",
    "                return item\n",
    "\n",
    "    def metrics_df(self):\n",
    "        return pd.json_normalize(self.experiments).drop(['train', 'test'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ExperimentTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets['source_train'].copy()\n",
    "test = datasets['source_test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(['date', 'time'])\n",
    "test = test.sort_values(['date', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index().rename(columns={'index': 'id'})\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_dataset(train)\n",
    "test = prepare_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.date == '2020-09-04'][['datetime', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.date == '2020-09-04'][['datetime', 'target']].head(20).plot(x = \"datetime\", y = \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.date == '2020-09-05'][['datetime', 'target']].head(20).plot(x = \"datetime\", y = \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(train.sort_values('datetime'), x='datetime', y=\"target\", hover_data=[\"date\", \"time\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'].min(), train['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date'].min(), test['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weather_pred'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weather_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['weather_pred'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weather_pred'][train['weather_pred'].fillna('').str.contains('ясн')].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weather_pred'].str.contains('ясн').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weather_fact'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из Kaggle, покомпонентое разложение, надо заставить его нормально работать\n",
    "\n",
    "# Multiplicative Decomposition \n",
    "multiplicative_decomposition = seasonal_decompose(train['target'], model='multiplicative', period=30)\n",
    "\n",
    "# Additive Decomposition\n",
    "additive_decomposition = seasonal_decompose(train['target'], model='additive', period=30)\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (15,15), 'figure.dpi': 70})\n",
    "multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `target` ровно год назад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.date == '2020-01-01'].head() # с id 8760 должны появиться предсказания baseline модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape[0] / (train.shape[0] + test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.date.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.date.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineYearAgo()\n",
    "model.fit(train.drop('target', axis=1), train['target'])\n",
    "\n",
    "# Пример невычислимого предсказания\n",
    "# df = train[train.date >= '2020-12-31'].drop('target', axis=1)\n",
    "# df['predict'] = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = train[train.date >= '2020-01-01'] # с этой даты baseline модель может выдать прогноз\n",
    "# df['predict'] = model.predict(df.drop('target', axis=1))\n",
    "# train_metrics = pd.json_normalize(evaluate(df['target'], df['predict']))\n",
    "# train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.add_experiment(model, train[train.date >= '2020-01-01'], test, \"Baseline: значение год назад относительно текущей даты\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.date >= '2020-01-01'].date.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = aggregated_daily_predictions(tracker.experiments[0]['train']).reset_index()\n",
    "pd.json_normalize(evaluate(df2['target'], df2['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(tracker.experiments[0]['train'], \"Train: hourly\")\n",
    "plot_prediction(df2, \"Train: daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(evaluate(df2['target'], df2['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(tracker.experiments[0]['test'], \"Test: hourly\")\n",
    "plot_prediction(df2, \"Test: daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophetModel = Prophet()\n",
    "prophetModel.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.add_experiment(prophetModel, train, test, \"Prophet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = test.merge(prophetModel.predict(test), on ='ds')\n",
    "forecast['predict'] = forecast['yhat']\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(evaluate(forecast['target'], forecast['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = aggregated_daily_predictions(forecast)\n",
    "pd.json_normalize(evaluate(df2['target'], df2['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tracker.metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.style.highlight_min(subset=['test_MAE', 'test_R^2', 'test_MSE', 'test_MAPE', 'test_RMSE'], color = 'green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
